{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2ab97d3",
   "metadata": {},
   "source": [
    "### Q1 Explain the architecture of LeNet-5 and its significance in the field of deep learning. \n",
    "\n",
    "\n",
    "\n",
    "LeNet-5 is a pioneering convolutional neural network (CNN) introduced by Yann LeCun et al. in 1998, designed for handwritten digit recognition (e.g., MNIST dataset). Its architecture consists of seven layers (excluding input) containing trainable parameters. These include convolutional layers, pooling layers, and fully connected layers.\n",
    "\n",
    "Input Layer:\n",
    "Input size: \n",
    "32×32 grayscale image.\n",
    "Preprocessing: Normalized pixel values between 0 and 1.\n",
    "Convolutional Layer 1 (C1):\n",
    "6 filters of size 5×5.\n",
    "Stride: 1, No padding.\n",
    "Output size: 28×28×6.\n",
    "Activation: Sigmoid (historically used, though ReLU is common today).\n",
    "Role: Extract local features like edges or textures.\n",
    "Pooling Layer 1 (S2):\n",
    "Subsampling (Average pooling) with 2×2 filter and stride 2.\n",
    "Output size: 14×14×6.\n",
    "Role: Reduces spatial resolution to make the model computationally efficient and more robust to spatial variations.\n",
    "Convolutional Layer 2 (C3):\n",
    "16 filters of size 5×5.\n",
    "Stride: 1, with select connectivity to previous layer’s feature maps (a unique design choice).\n",
    "Output size: 10×10×16.\n",
    "Role: Extract more complex features.\n",
    "Pooling Layer 2 (S4):\n",
    "Subsampling (Average pooling) with 2×2 filter and stride 2.\n",
    "Output size: 5×5×16.\n",
    "Role: Further downsample spatial dimensions.\n",
    "Fully Connected Layer 1 (F5):\n",
    "Fully connected layer with 120 neurons.\n",
    "Input size: Flattened 400 units from S4.\n",
    "Activation: Sigmoid.\n",
    "Role: Combine features for higher-level representation.\n",
    "Fully Connected Layer 2 (F6):\n",
    "Fully connected layer with 84 neurons.\n",
    "Activation: Sigmoid.\n",
    "Role: Further abstraction and representation of learned features.\n",
    "Output Layer:\n",
    "Fully connected layer with 10 neurons (one for each digit class, 0-9).\n",
    "Activation: Softmax.\n",
    "Role: Produce probability distribution for digit classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c34e56f",
   "metadata": {},
   "source": [
    "### Q2 Describe the key components of LeNet-5 and their roles in the network.\n",
    "\n",
    "\n",
    "\n",
    "Input Layer: Input size: 32×32 grayscale image. Preprocessing: Normalized pixel values between 0 and 1. Convolutional Layer 1 (C1): 6 filters of size 5×5. Stride: 1, No padding. Output size: 28×28×6. Activation: Sigmoid (historically used, though ReLU is common today). Role: Extract local features like edges or textures. Pooling Layer 1 (S2): Subsampling (Average pooling) with 2×2 filter and stride 2. Output size: 14×14×6. Role: Reduces spatial resolution to make the model computationally efficient and more robust to spatial variations. Convolutional Layer 2 (C3): 16 filters of size 5×5. Stride: 1, with select connectivity to previous layer’s feature maps (a unique design choice). Output size: 10×10×16. Role: Extract more complex features. Pooling Layer 2 (S4): Subsampling (Average pooling) with 2×2 filter and stride 2. Output size: 5×5×16. Role: Further downsample spatial dimensions. Fully Connected Layer 1 (F5): Fully connected layer with 120 neurons. Input size: Flattened 400 units from S4. Activation: Sigmoid. Role: Combine features for higher-level representation. Fully Connected Layer 2 (F6): Fully connected layer with 84 neurons. Activation: Sigmoid. Role: Further abstraction and representation of learned features. Output Layer: Fully connected layer with 10 neurons (one for each digit class, 0-9). Activation: Softmax. Role: Produce probability distribution for digit classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ba9b6",
   "metadata": {},
   "source": [
    "### Q3 Discuss the limitations of LeNet-5 and how subsequent architectures like AlexNet addressed these limitations.\n",
    "\n",
    "\n",
    "\n",
    "Limited Computational Power Usage:\n",
    "\n",
    "LeNet-5 Limitation: Designed in the 1990s, it was constrained by the computational resources of the time, which limited its depth, number of parameters, and training scale.\n",
    "AlexNet Solution:\n",
    "Utilized GPUs for parallel processing, enabling deeper and more complex architectures.\n",
    "Trained on a significantly larger dataset (ImageNet).\n",
    "\n",
    "Shallow Architecture:\n",
    "\n",
    "LeNet-5 Limitation: Consists of only two convolutional layers, which restricts its ability to learn hierarchical features from complex datasets.\n",
    "AlexNet Solution:\n",
    "Increased depth with 5 convolutional layers and 3 fully connected layers.\n",
    "Allowed for more detailed feature extraction and better performance on larger datasets.\n",
    "\n",
    "Small Input Size:\n",
    "\n",
    "LeNet-5 Limitation: Designed for 32×32 grayscale images, which is inadequate for high-resolution, real-world data.\n",
    "AlexNet Solution:\n",
    "Designed to handle 224×224×3 color images.\n",
    "Incorporated larger receptive fields and filters to process detailed, high-resolution images.\n",
    "\n",
    "Monochromatic Data Focus:\n",
    "\n",
    "LeNet-5 Limitation: Primarily designed for grayscale images (e.g., MNIST), limiting its application to more general tasks.\n",
    "AlexNet Solution:\n",
    "Built for RGB color images, enabling its use in diverse computer vision applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d77cbb7",
   "metadata": {},
   "source": [
    "### Q4 Explain the architecture of AlexNet and its contributions to the advancement of deep learning.\n",
    "\n",
    "\n",
    "Input Layer:\n",
    "    \n",
    "Accepts RGB images of size 227×227×3.\n",
    "Performs preprocessing, including mean subtraction.\n",
    "\n",
    "Convolutional Layers:\n",
    "    \n",
    "Layer 1:\n",
    "96 filters of size 11×11, stride 4.\n",
    "Produces feature maps of size 55×55×96.\n",
    "Followed by ReLU activation and local response normalization (LRN).\n",
    "Layer 2:\n",
    "256 filters of size 5×5, stride 1.\n",
    "Feature maps: \n",
    "27×27×256.\n",
    "ReLU activation and LRN applied.\n",
    "Layer 3, 4, 5:\n",
    "384, 384, and 256 filters of size 3×3, stride 1.\n",
    "These layers progressively refine feature maps.\n",
    "\n",
    "Pooling Layers:\n",
    "    \n",
    "Max Pooling with 3×3 filters and stride 2 is applied after the first, second, and fifth convolutional layers.\n",
    "Role: Reduces spatial dimensions, retains important features, and introduces spatial invariance.\n",
    "    \n",
    "Fully Connected Layers:\n",
    "    \n",
    "FC1: 4096 neurons with ReLU activation.\n",
    "FC2: 4096 neurons with ReLU activation.\n",
    "FC3: 1000 neurons (one for each class in ImageNet) with softmax activation.\n",
    "    \n",
    "Dropout Layers:\n",
    "    \n",
    "Introduced in the fully connected layers to prevent overfitting by randomly deactivating neurons during training.\n",
    "\n",
    "ReLU Activation:\n",
    "    \n",
    "Applied after every convolutional and fully connected layer.\n",
    "ReLU improves gradient flow and accelerates training compared to sigmoid or tanh activations.\n",
    "\n",
    "Local Response Normalization (LRN):\n",
    "    \n",
    "Encourages competition among neurons, improving generalization.\n",
    "Applied after the first two convolutional layers.\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b99a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ace61cef",
   "metadata": {},
   "source": [
    "### Q5 Compare and contrast the architectures of LeNet-5 and AlexNet. Discuss their similarities, differences, and respective contributions to the field of deep learning.\n",
    "\n",
    "\n",
    "Similarities:\n",
    "\n",
    "Convolutional Neural Networks (CNNs):\n",
    "\n",
    "Both architectures use convolutional layers to extract spatial features from images.\n",
    "\n",
    "Pooling Layers:\n",
    "\n",
    "Both employ pooling layers to reduce spatial dimensions and achieve translational invariance.\n",
    "\n",
    "Fully Connected Layers:\n",
    "\n",
    "Both use fully connected layers at the end to aggregate high-level features and make predictions.\n",
    "\n",
    "Activation Functions:\n",
    "\n",
    "Both use non-linear activation functions, although the specific types differ (LeNet-5 uses sigmoid/tanh; AlexNet uses ReLU).\n",
    "\n",
    "Layered Design:\n",
    "\n",
    "Both follow a hierarchical structure, progressively learning from simple to complex features.\n",
    "\n",
    "\n",
    "Differences:\n",
    "\n",
    "Input Size: LeNet processes 32×32 grayscale images whereas AlexNet handles 227×227 RGB images.\n",
    "\n",
    "Dataset Focus: LeNet-5 was designed for small-scale datasets like MNIST, whereas AlexNet targeted large-scale datasets like ImageNet.\n",
    "\n",
    "Depth: LeNet-5 is shallow with 2 convolutional layers, while AlexNet is deeper with 5 convolutional layers.\n",
    "\n",
    "Filters: LeNet-5 uses fewer filters per layer (6-16), whereas AlexNet uses significantly more (96-384).\n",
    "\n",
    "Regularization: AlexNet incorporates dropout to reduce overfitting, while LeNet-5 does not use explicit regularization techniques.\n",
    "\n",
    "GPU Utilization: LeNet-5 was designed for CPU execution, while AlexNet leveraged GPUs to enable training of deeper models.\n",
    "\n",
    "Normalization: AlexNet introduced Local Response Normalization (LRN) to encourage competition among neurons, which is absent in LeNet-5.\n",
    "\n",
    "Target Dataset: LeNet-5 focuses on simpler grayscale images, while AlexNet is built for complex, high-resolution RGB images.\n",
    "\n",
    "\n",
    "Contributions to the Field\n",
    "LeNet-5:\n",
    "\n",
    "Introduced CNNs as a viable model for computer vision tasks.\n",
    "Demonstrated the efficacy of convolutional and pooling layers for digit recognition.\n",
    "\n",
    "AlexNet:\n",
    "\n",
    "Revolutionized computer vision with a dramatic improvement in ImageNet performance.\n",
    "Popularized deep learning by demonstrating its scalability to large datasets.\n",
    "Introduced practical techniques such as ReLU activation, dropout regularization, and GPU utilization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6dc79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b17db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
